#!/usr/bin/env python3
"""
test_main_pipeline.py - Test completo del pipeline main.py con wrappers integrados

Este script verifica que todo el pipeline funcione correctamente:
1. Inicializaci√≥n de ProductionInferenceEngine 
2. Carga de modelos PyTorch/ONNX/TFLite
3. YOLO detection
4. ConvNextPose inference
5. RootNet integration
6. Post-procesamiento completo
"""

import os
import sys
import logging
import numpy as np
import cv2
import torch
from pathlib import Path
import argparse
import time

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# A√±adir paths
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def create_test_image(width=640, height=480):
    """Crear imagen de prueba con figura humana simulada"""
    img = np.random.randint(50, 200, (height, width, 3), dtype=np.uint8)
    
    # Simular figura humana (rect√°ngulo vertical)
    person_x = width // 2 - 50
    person_y = height // 2 - 100
    person_w = 100
    person_h = 200
    
    # Dibujar figura humana simulada
    cv2.rectangle(img, (person_x, person_y), (person_x + person_w, person_y + person_h), (120, 150, 180), -1)
    
    # Simular cabeza
    cv2.circle(img, (person_x + person_w//2, person_y + 20), 15, (200, 180, 150), -1)
    
    logger.info(f"Created test image: {width}x{height}")
    logger.info(f"Simulated person bbox: [{person_x}, {person_y}, {person_w}, {person_h}]")
    
    return img, [person_x, person_y, person_w, person_h]

def test_yolo_detector():
    """Test del detector YOLO"""
    logger.info("üîÑ Testing YOLO detector...")
    
    try:
        # Import here to catch errors
        sys.path.insert(0, os.path.dirname(__file__))
        from main import ProductionYOLODetector
        
        detector = ProductionYOLODetector()
        
        if detector.detector is None:
            logger.warning("‚ö†Ô∏è YOLO not available - skipping detection test")
            return True, []
        
        # Create test image
        test_img, expected_bbox = create_test_image()
        
        # Test detection
        detections = detector.detect_persons(test_img, detection_freq=1, conf_threshold=0.3)
        
        logger.info(f"‚úÖ YOLO detection completed")
        logger.info(f"   - Detections found: {len(detections)}")
        
        # If no detections, use simulated bbox
        if len(detections) == 0:
            logger.info("   - Using simulated bbox for testing")
            detections = [expected_bbox]
        
        return True, detections
        
    except Exception as e:
        logger.error(f"‚ùå YOLO detector test failed: {e}")
        import traceback
        traceback.print_exc()
        return False, []

def test_inference_engine(backend='pytorch'):
    """Test del motor de inferencia"""
    logger.info(f"üîÑ Testing inference engine with backend: {backend}")
    
    try:
        # Import engine
        from main import ProductionInferenceEngine
        
        # Check model exists
        model_path = "models/model_opt_S.pth"
        if not os.path.exists(model_path):
            logger.error(f"‚ùå Model not found: {model_path}")
            return False
        
        # Initialize engine
        engine = ProductionInferenceEngine(model_path=model_path, backend=backend)
        
        if engine.active_backend is None:
            logger.error(f"‚ùå Failed to initialize {backend} backend")
            return False
        
        logger.info(f"‚úÖ Inference engine initialized: {engine.active_backend}")
        
        # Test inference
        test_img, expected_bbox = create_test_image(256, 256)  # ConvNext input size
        
        # Test inference
        output = engine.infer(test_img)
        
        if output is not None:
            logger.info(f"‚úÖ Inference successful")
            logger.info(f"   - Output shape: {output.shape}")
            logger.info(f"   - Output dtype: {output.dtype}")
            return True
        else:
            logger.error("‚ùå Inference returned None")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Inference engine test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_full_pipeline():
    """Test del pipeline completo"""
    logger.info("üîÑ Testing full pipeline...")
    
    try:
        from main import ProductionV4Processor
        
        # Check if we can create the processor
        processor = ProductionV4Processor(
            model_path="models/model_opt_S.pth",
            backend='pytorch',
            preset='quality_focused'  # Sin threading para test
        )
        
        # Create test image
        test_img, expected_bbox = create_test_image()
        
        # Process single frame
        result = processor.process_frame(test_img)
        
        if result is not None:
            poses_2d, poses_3d, fps_info = result
            logger.info(f"‚úÖ Full pipeline successful")
            logger.info(f"   - 2D poses: {len(poses_2d) if poses_2d else 0}")
            logger.info(f"   - 3D poses: {len(poses_3d) if poses_3d else 0}")
            logger.info(f"   - FPS info: {fps_info}")
            return True
        else:
            logger.warning("‚ö†Ô∏è Pipeline returned None (might be normal)")
            return True  # Not necessarily an error
            
    except Exception as e:
        logger.error(f"‚ùå Full pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_convnext_wrapper_integration():
    """Test espec√≠fico del ConvNextWrapper con RootNet"""
    logger.info("üîÑ Testing ConvNextWrapper + RootNet integration...")
    
    try:
        from convnext_wrapper import ConvNextWrapper
        
        # Initialize wrapper
        wrapper = ConvNextWrapper(
            model_path="models/model_opt_S.pth",
            input_size=256,
            output_size=32
        )
        
        # Load PyTorch model
        success = wrapper.load_pytorch_model(joint_num=18)
        
        if not success:
            logger.error("‚ùå Failed to load ConvNextWrapper")
            return False
        
        # Test pose prediction with RootNet integration
        test_img, bbox = create_test_image()
        
        pose_2d, pose_3d = wrapper.predict_pose_full(
            original_img=test_img,
            bbox=bbox,
            backend='pytorch'
        )
        
        if pose_2d is not None and pose_3d is not None:
            logger.info(f"‚úÖ ConvNext + RootNet integration successful")
            logger.info(f"   - 2D pose shape: {pose_2d.shape}")
            logger.info(f"   - 3D pose shape: {pose_3d.shape}")
            logger.info(f"   - Sample 2D joint: {pose_2d[0]}")
            logger.info(f"   - Sample 3D joint: {pose_3d[0]}")
            return True
        else:
            logger.error("‚ùå Pose prediction returned None")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå ConvNext wrapper integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_config_paths():
    """Test de configuraci√≥n de paths"""
    logger.info("üîÑ Testing configuration paths...")
    
    try:
        from config_paths import CONVNEXT_POSE_PATH, ROOTNET_PATH, MODEL_PATH
        
        logger.info(f"‚úÖ Configuration loaded:")
        logger.info(f"   - ConvNextPose: {CONVNEXT_POSE_PATH}")
        logger.info(f"   - RootNet: {ROOTNET_PATH}")
        logger.info(f"   - Model: {MODEL_PATH}")
        
        # Check if paths exist
        paths_ok = True
        
        if not os.path.exists(CONVNEXT_POSE_PATH):
            logger.warning(f"‚ö†Ô∏è ConvNextPose path not found: {CONVNEXT_POSE_PATH}")
            paths_ok = False
        
        if not os.path.exists(ROOTNET_PATH):
            logger.warning(f"‚ö†Ô∏è RootNet path not found: {ROOTNET_PATH}")
            paths_ok = False
            
        if not os.path.exists(MODEL_PATH):
            logger.warning(f"‚ö†Ô∏è Model path not found: {MODEL_PATH}")
            paths_ok = False
        
        return paths_ok
        
    except ImportError as e:
        logger.error(f"‚ùå Failed to load config_paths: {e}")
        return False

def main():
    """Funci√≥n principal de prueba"""
    parser = argparse.ArgumentParser(description='Test complete main.py pipeline')
    parser.add_argument('--backend', choices=['pytorch', 'onnx', 'tflite'], 
                       default='pytorch', help='Backend to test')
    parser.add_argument('--skip-yolo', action='store_true', 
                       help='Skip YOLO detector test')
    parser.add_argument('--skip-full', action='store_true', 
                       help='Skip full pipeline test')
    
    args = parser.parse_args()
    
    logger.info("üöÄ Starting complete main.py pipeline tests")
    logger.info("=" * 60)
    
    all_passed = True
    
    # Test 1: Configuration
    logger.info("\nüìã Test 1: Configuration Paths")
    if not test_config_paths():
        logger.error("‚ùå Configuration test failed")
        all_passed = False
    
    # Test 2: YOLO Detector
    if not args.skip_yolo:
        logger.info("\nüéØ Test 2: YOLO Detector")
        yolo_ok, detections = test_yolo_detector()
        if not yolo_ok:
            logger.error("‚ùå YOLO detector test failed")
            all_passed = False
    
    # Test 3: Inference Engine
    logger.info(f"\nüß† Test 3: Inference Engine ({args.backend})")
    if not test_inference_engine(backend=args.backend):
        logger.error(f"‚ùå Inference engine test failed ({args.backend})")
        all_passed = False
    
    # Test 4: ConvNext + RootNet Integration
    logger.info("\nüîó Test 4: ConvNext + RootNet Integration")
    if not test_convnext_wrapper_integration():
        logger.error("‚ùå ConvNext wrapper integration test failed")
        all_passed = False
    
    # Test 5: Full Pipeline
    if not args.skip_full:
        logger.info("\nüèÅ Test 5: Full Pipeline")
        if not test_full_pipeline():
            logger.error("‚ùå Full pipeline test failed")
            all_passed = False
    
    # Results
    logger.info("\n" + "=" * 60)
    if all_passed:
        logger.info("üéâ ALL TESTS PASSED!")
        logger.info("‚úÖ main.py pipeline is ready for production")
        logger.info("\nüí° Next steps:")
        logger.info("   - Run: python main.py --preset ultra_fast --backend pytorch")
        logger.info("   - Or: python main.py --preset quality_focused --backend pytorch")
    else:
        logger.error("‚ùå SOME TESTS FAILED")
        logger.error("üîß Check the errors above and fix configuration/paths")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
