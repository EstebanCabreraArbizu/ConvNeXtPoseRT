# ConvNeXt Pose Real-time with Quantized YOLO Integration

High-performance real-time pose estimation pipeline combining ConvNeXt pose networks with quantized YOLO detection for optimal latency and accuracy.

## üöÄ Key Features

### ‚ö° Performance Optimizations
- **Quantized YOLO Integration**: ONNX INT8 quantized YOLO models for 2-3x faster person detection
- **Multi-Backend Support**: PyTorch, ONNX, and TFLite backends for pose estimation
- **Intelligent Caching**: Smart detection caching with adaptive frame skipping
- **Hardware-Aware Configuration**: Automatic optimization based on available hardware

### üéØ Detection & Pose Estimation
- **Fast Person Detection**: Quantized YOLO11 models with sub-10ms detection times
- **2D/3D Pose Estimation**: Optional RootNet integration for 3D depth estimation
- **Multi-Person Support**: Efficient handling of multiple persons per frame
- **Production-Ready**: Robust error handling and fallback mechanisms

### üîß Technical Features
- **Hybrid YOLO Processing**: ONNX quantized with PyTorch fallback
- **Adaptive Preprocessing**: Hardware-optimized image processing
- **Thread Pool Management**: Controlled parallel processing for pose estimation
- **Memory Efficient**: Optimized memory usage and garbage collection

## üìä Performance Results

| Backend | Detection (ms) | Pose (ms) | Total FPS | Notes |
|---------|---------------|-----------|-----------|-------|
| ONNX Quantized + PyTorch | 3-8 | 15-25 | 25-30 | Best balance |
| PyTorch + PyTorch | 8-15 | 15-25 | 18-25 | Full PyTorch |
| ONNX + ONNX | 3-8 | 8-15 | 35-45 | Fastest |

*Results on typical consumer hardware (CPU-optimized)*

## üõ†Ô∏è Installation

### Prerequisites
```bash
# Core dependencies
pip install torch torchvision
pip install ultralytics
pip install onnxruntime
pip install opencv-python
pip install numpy

# Optional: GPU acceleration
pip install onnxruntime-gpu

# Optional: TensorFlow Lite support
pip install tensorflow
```

### Project Setup
```bash
# Clone the repository
git clone <your-repo-url>
cd ConvNeXtPoseRT

# Download and setup YOLO models
python setup_models.py

# Test the integration
python test_integration.py
```

## üöÄ Quick Start

### Basic Usage
```bash
# Webcam with ultra-fast preset (quantized YOLO)
python main.py --preset ultra_fast --backend pytorch

# Video file with quality focus
python main.py --input video.mp4 --preset quality_focused --backend onnx

# Enable 3D pose estimation (requires RootNet)
python main.py --preset speed_balanced --backend pytorch --enable_3d
```

### Performance Presets

#### Ultra Fast (15+ FPS)
```bash
python main.py --preset ultra_fast --backend pytorch
```
- Target: 15+ FPS
- YOLO: 320px quantized
- Detection: Every 4th frame
- Best for: Real-time applications

#### Speed Balanced (12+ FPS)
```bash
python main.py --preset speed_balanced --backend onnx
```
- Target: 12+ FPS
- YOLO: 416px quantized
- Detection: Every 3rd frame
- Best for: Quality-speed balance

#### Quality Focused (10+ FPS)
```bash
python main.py --preset quality_focused --backend onnx --enable_3d
```
- Target: 10+ FPS
- YOLO: 512px quantized
- Detection: Every 2nd frame
- Best for: High-quality results

## üî¨ Advanced Usage

### Model Setup and Conversion
```bash
# Download and convert YOLO models
python setup_models.py

# Convert specific model
python setup_models.py --model yolo11s.pt

# Skip quantization (if not supported)
python setup_models.py --no-quantize

# List available models
python setup_models.py --list
```

### Performance Benchmarking
```bash
# Run performance benchmarks
python demo_quantized.py --benchmark --iterations 100

# Real-time demo with metrics
python demo_quantized.py --demo --duration 30

# Quick integration test
python demo_quantized.py
```

### Custom Configuration
```python
from main import ProductionV4Processor

# Custom processor
processor = ProductionV4Processor(
    model_path='models/model_opt_S.pth',
    preset='ultra_fast',
    backend='pytorch',
    enable_3d=False
)

# Process frame
poses, stats = processor.process_frame(frame)
print(f"FPS: {stats['instant_fps']:.1f}")
```

## üß™ Testing

### Integration Tests
```bash
# Run all integration tests
python test_integration.py

# Test individual components
python -c "from main import ProductionYOLODetector; print('‚úÖ YOLO OK')"
python -c "from main import ProductionInferenceEngine; print('‚úÖ Pose OK')"
```

### Performance Validation
```bash
# Benchmark YOLO detection only
python demo_quantized.py --benchmark

# Full pipeline benchmark
python demo_quantized.py --benchmark --iterations 50
```

## üìÅ Project Structure

```
ConvNeXtPoseRT/
‚îú‚îÄ‚îÄ main.py                 # Main pipeline with quantized YOLO
‚îú‚îÄ‚îÄ setup_models.py         # Model download and conversion
‚îú‚îÄ‚îÄ demo_quantized.py       # Performance demo and benchmarks
‚îú‚îÄ‚îÄ test_integration.py     # Integration tests
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ convnext_wrapper.py # ConvNeXt model wrapper
‚îÇ   ‚îî‚îÄ‚îÄ root_wrapper.py     # RootNet 3D wrapper
‚îú‚îÄ‚îÄ models/                 # Model files (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ model_opt_S.pth     # ConvNeXt pose model
‚îÇ   ‚îú‚îÄ‚îÄ yolo11n.pt          # YOLO PyTorch model
‚îÇ   ‚îî‚îÄ‚îÄ *.onnx              # Quantized ONNX models
‚îú‚îÄ‚îÄ configs/                # Configuration files
‚îú‚îÄ‚îÄ tests/                  # Test data and scripts
‚îî‚îÄ‚îÄ docs/                   # Documentation
```

## ‚öôÔ∏è Configuration

### Hardware Optimization
The system automatically detects and optimizes for your hardware:

- **GPU Available**: Uses CUDA providers, increased batch sizes
- **CPU Only**: Optimizes thread counts, uses quantized models
- **Memory Constrained**: Reduces cache sizes, enables aggressive optimization

### Manual Tuning
```python
# Custom YOLO detector
detector = ProductionYOLODetector(
    model_path='models/yolo11n.pt',
    input_size=640  # Adjust based on speed/accuracy needs
)

# Custom inference engine
engine = ProductionInferenceEngine(
    model_path='models/model_opt_S.pth',
    backend='onnx'  # pytorch, onnx, tflite
)
```

## üêõ Troubleshooting

### Common Issues

#### ONNX Model Not Found
```bash
# Download and convert models
python setup_models.py
```

#### Slow Performance
```bash
# Use faster preset
python main.py --preset ultra_fast

# Check hardware optimization
python demo_quantized.py  # Shows detected configuration
```

#### 3D Estimation Fails
```bash
# Check RootNet availability
python -c "from main import ROOTNET_AVAILABLE; print(f'RootNet: {ROOTNET_AVAILABLE}')"

# Use 2D mode
python main.py --preset ultra_fast  # 3D disabled by default
```

### Performance Issues
1. **Low FPS**: Try `ultra_fast` preset or reduce input resolution
2. **High Memory**: Disable threading or reduce cache sizes
3. **Quantization Errors**: Use `--no-quantize` flag in setup

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`python test_integration.py`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open Pull Request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- **ConvNeXt Pose**: Original pose estimation network
- **YOLO**: Real-time object detection
- **ONNX Runtime**: Optimized inference engine
- **RootNet**: 3D pose estimation depth network

## üìà Changelog

### v2.0.0 - Quantized YOLO Integration
- ‚úÖ Added ONNX quantized YOLO support
- ‚úÖ Improved detection latency by 2-3x
- ‚úÖ Enhanced hardware-aware optimization
- ‚úÖ Added comprehensive benchmarking tools
- ‚úÖ Robust fallback mechanisms

### v1.0.0 - Initial Release
- ‚úÖ ConvNeXt pose estimation pipeline
- ‚úÖ Multi-backend support
- ‚úÖ RootNet 3D integration
- ‚úÖ Production-ready optimization